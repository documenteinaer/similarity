{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import sys, os, random\n",
    "# from compare_locations import compare_locations\n",
    "\n",
    "datadir = \"../data.upb/precis/01-precis-redmi-pixel4a/nowl/\"\n",
    "#datadir = \"../data.upb/precis/02-precis-redmi-pixel4a/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parter - face level \n",
    "#pix_etaje = [\"0-pixel-04-06-2021_19-34-41.json\"]\n",
    "#red_etaje = [\"0-redmi-04-06-2021_19-33-47.json\"]\n",
    "\n",
    "# whole building - hip level \n",
    "pix_etaje = [\n",
    "\"0-pixel-04-03-2021_15-32-38.json.gz\",\n",
    " \"1-pixel-25-02-2021_21-16-46.json.gz\",\n",
    " \"2-pixel-25-02-2021_16-27-45.json.gz\",\n",
    " \"3-pixel-04-03-2021_16-18-50.json.gz\",\n",
    " \"4-pixel-04-03-2021_16-43-50.json.gz\",\n",
    " \"5-pixel-04-03-2021_17-11-32.json.gz\",\n",
    " \"6-pixel-17-03-2021_12-52-29.json.gz\",\n",
    " \"7-pixel-17-03-2021_13-14-36.json.gz\"\n",
    "]\n",
    "\n",
    "red_etaje = [\n",
    "\"0-redmi-04-03-2021_15-31-12.json.gz\"#,\n",
    "# \"1-redmi-25-02-2021_21-16-10.json\",\n",
    "# \"2-redmi-25-02-2021_16-27-08.json\",\n",
    "# \"3-redmi-04-03-2021_16-18-52.json\",\n",
    "# \"4-redmi-04-03-2021_16-43-45.json\",\n",
    "# \"5-redmi-04-03-2021_17-11-30.json\",\n",
    "# \"6-redmi-17-03-2021_12-52-29.json\",\n",
    "# \"7-redmi-17-03-2021_13-14-39.json\"\n",
    "]\n",
    "\n",
    "\n",
    "retaje = []\n",
    "for e in red_etaje: \n",
    "    json_file = os.path.join(datadir, e)\n",
    "    etaj = load_dataset_json(json_file)\n",
    "    retaje.append(etaj)\n",
    "\n",
    "petaje = []\n",
    "for e in pix_etaje: \n",
    "    json_file = os.path.join(datadir, e)\n",
    "    etaj = load_dataset_json(json_file)\n",
    "    petaje.append(etaj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from scipy.stats import ks_2samp, chisquare\n",
    "import copy \n",
    "\n",
    "def merge_wifi_fingerprints(flist):\n",
    "    fingerprint = copy.deepcopy(flist[0])\n",
    "    for f2 in copy.deepcopy(flist[1:]):\n",
    "        if not \"wifi\" in f2.keys():\n",
    "            continue\n",
    "        for mac in f2[\"wifi\"].keys():\n",
    "            if not mac in fingerprint[\"wifi\"].keys():\n",
    "                fingerprint[\"wifi\"][mac] = f2[\"wifi\"][mac]\n",
    "                #fingerprint[\"wifi\"][mac]['rssi'] = []\n",
    "            else:\n",
    "                fingerprint[\"wifi\"][mac]['rssi'].extend(f2[\"wifi\"][mac]['rssi'])\n",
    "            fingerprint[\"wifi\"][mac]['rssi'].sort()    \n",
    "    return fingerprint\n",
    "\n",
    "\n",
    "def compare_locations(c1, c2, simil_method = braycurtis,  selection = 'Average'):\n",
    "    rssi1 = []\n",
    "    rssi2 = []\n",
    "    w = [] #weight for braycurtis\n",
    "    \n",
    "    # take the first fingerprint in the list \n",
    "    #wifi1 = c1['fingerprints'][0]['wifi']\n",
    "    #wifi2 = c2['fingerprints'][0]['wifi']\n",
    "\n",
    "    # take a random fingerprint in the list \n",
    "    #wifi1 = c1['fingerprints'][random.randint(0,3)]['wifi']\n",
    "    #wifi2 = c2['fingerprints'][random.randint(0,3)]['wifi']\n",
    "\n",
    "    # first & third - as if measuring twice at 180 degrees\n",
    "    wifi1 = merge_wifi_fingerprints([c1['fingerprints'][0], c1['fingerprints'][2]])['wifi']\n",
    "    wifi2 = merge_wifi_fingerprints([c2['fingerprints'][0], c2['fingerprints'][2]])['wifi']\n",
    "    \n",
    "    #merge all existing fingerprints for each collection\n",
    "    #wifi1 = merge_wifi_fingerprints(c1['fingerprints'])['wifi']\n",
    "    #wifi2 = merge_wifi_fingerprints(c2['fingerprints'])['wifi']\n",
    "    \n",
    "    # all power received by the query\n",
    "    power1 = 0\n",
    "    for ap in wifi1:\n",
    "        power1 += np.sum(adjust_rssi(wifi1[ap]['rssi']))\n",
    "        \n",
    "    common_aps = list(set(wifi1.keys()) & set(wifi2.keys()))\n",
    "    #print(\"common aps=\", len(common_aps))\n",
    "    \n",
    "    # No APs in common -> similarity = 1\n",
    "    if not common_aps:\n",
    "        return 1\n",
    "\n",
    "    # TODO: find the best metric\n",
    "    # If not enough common APs -> similarity = 1\n",
    "    if len(common_aps) * 10 < len(wifi1.keys()) or len(common_aps) < 3:\n",
    "        return 1\n",
    "\n",
    "    for ap in common_aps:\n",
    "        \n",
    "        if selection == 'Bestdir':\n",
    "            for f1 in c1['fingerprints']: # all fingerprint dirs in the query \n",
    "                if not ap in f1['wifi'].keys():\n",
    "                    continue\n",
    "                m1 = np.average(adjust_rssi(f1['wifi'][ap]['rssi']))\n",
    "                best = 100                \n",
    "                for f2 in c2['fingerprints']: \n",
    "                    if not ap in f2['wifi'].keys():\n",
    "                        continue\n",
    "                    m2 = np.average(adjust_rssi(f2['wifi'][ap]['rssi']))\n",
    "                    if(math.fabs(m2-m1)) < best:  # find one dir with closest RSSI\n",
    "                        best = math.fabs(m2-m1)\n",
    "                        bestf = m2\n",
    "                rssi1.append(m1)\n",
    "                rssi2.append(bestf)\n",
    "                \n",
    "        # Take only the first RSSI value                \n",
    "        if selection == 'First':\n",
    "            rssi1.append(wifi1[ap]['rssi'][0])\n",
    "            rssi2.append(wifi2[ap]['rssi'][0])\n",
    "\n",
    "        # Make an average of all RSSI values\n",
    "        if selection == 'Average':\n",
    "            rssi1.append(np.average(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.average(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "            w.append(min(len(wifi1[ap]['rssi']), len(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Median':\n",
    "            rssi1.append(np.median(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.median(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Mean':\n",
    "            rssi1.append(np.mean(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.mean(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Std':\n",
    "            rssi1.append(np.std(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.std(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Max':\n",
    "            rssi1.append(np.max(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.max(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "            \n",
    "        if selection == 'KS':\n",
    "            _, p = ks_2samp(wifi1[ap]['rssi'], wifi2[ap]['rssi'])\n",
    "            rssi1.append(p)\n",
    "            rssi2.append(1.0)\n",
    "\n",
    "        if selection == 'Tempered':\n",
    "            rss_1.append(np.average(rssi_v[index][key]) * random.uniform(0.8, 1.2))\n",
    "            rss_2.append(np.average(rssi_v[r][key]) * random.uniform(0.8, 1.2))\n",
    "\n",
    "    #print(f\"1={rssi1}\\n2={rssi2}\\ncommon={common_aps}\")\n",
    "    if selection != 'KS':\n",
    "        rssi1 = list(map(lambda x: x - np.mean(rssi1), rssi1))\n",
    "        rssi2 = list(map(lambda x: x - np.mean(rssi2), rssi2))\n",
    "    return simil_method(tuple(rssi1), tuple(rssi2))\n",
    "#        return simil_method(tuple(rssi1), tuple(rssi2))*sum(rssi1)/power1\n",
    "# weigh final result with used power/total power   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macs =  83\n",
      "macs =  75\n",
      "macs =  73\n",
      "macs =  75\n",
      "macs =  68\n",
      "macs =  76\n",
      "macs =  74\n",
      "macs =  50\n",
      "l =  27\n",
      "83 49 27  3  0  0  0  0 \n",
      "49 75 53 29  0  0  0  0 \n",
      "27 53 73 48 19  0  0  0 \n",
      " 3 29 48 75 44 24  0  0 \n",
      " 0  0 19 44 68 48 24  0 \n",
      " 0  0  0 24 48 76 49 25 \n",
      " 0  0  0  0 24 49 74 50 \n",
      " 0  0  0  0  0 25 50 50 \n",
      "Difference:\n",
      " 0 34 56 80 83 83 83 83 \n",
      "26  0 22 46 75 75 75 75 \n",
      "46 20  0 25 54 73 73 73 \n",
      "72 46 27  0 31 51 75 75 \n",
      "68 68 49 24  0 20 44 68 \n",
      "76 76 76 52 28  0 27 51 \n",
      "74 74 74 74 50 25  0 24 \n",
      "50 50 50 50 50 25  0  0 \n"
     ]
    }
   ],
   "source": [
    "macs = []\n",
    "for e in petaje:     \n",
    "    macse = set([])\n",
    "    for c in e:\n",
    "        f = c['fingerprints']\n",
    "        allf = merge_wifi_fingerprints(f)['wifi']\n",
    "        macse = macse | set(allf.keys())\n",
    "    macs.append(macse)    \n",
    "    print(\"macs = \", len(macse))    \n",
    "    \n",
    "print(\"l = \", len(macs[0] & macs[2]))    \n",
    "    \n",
    "for me in macs:\n",
    "    for ne in macs: \n",
    "        print(\"%2d \" % len(me & ne), end='')\n",
    "    print(\"\")    \n",
    "\n",
    "print(\"Difference:\")\n",
    "for me in macs:\n",
    "    for ne in macs: \n",
    "        print(\"%2d \" % len(me - ne), end='')\n",
    "    print(\"\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
