{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " - no merging APs - separate APs work better \n",
    " - Average works best (99% 1 step + 2 steps, pixel) (98% 1 step + 2 steps, redmi)\n",
    " - weighting by power used / total power received doesn't work \n",
    " - KS doesnt work \n",
    " - Average > Median > Max \n",
    " - random direction = disaster \n",
    " - sometimes RSSI data from an AP is missing (not received) -> misclassification\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import sys, os, random\n",
    "# from compare_locations import compare_locations\n",
    "\n",
    "datadir = \"./data/nowl/\"\n",
    "# preprocessed already, with \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_etaje = [\n",
    "\"0-pixel-04-03-2021_15-32-38.json\",\n",
    "\"1-pixel-25-02-2021_21-16-46.json\",\n",
    "\"2-pixel-25-02-2021_16-27-45.json\",\n",
    "\"3-pixel-04-03-2021_16-18-50.json\",\n",
    "\"4-pixel-04-03-2021_16-43-50.json\",\n",
    "\"5-pixel-04-03-2021_17-11-32.json\",\n",
    "\"6-pixel-17-03-2021_12-52-29.json\",\n",
    "\"7-pixel-17-03-2021_13-14-36.json\"]\n",
    "\n",
    "red_etaje = [\n",
    "\"0-redmi-04-03-2021_15-31-12.json\",\n",
    "\"1-redmi-25-02-2021_21-16-10.json\",\n",
    "\"2-redmi-25-02-2021_16-27-08.json\",\n",
    "\"3-redmi-04-03-2021_16-18-52.json\",\n",
    "\"4-redmi-04-03-2021_16-43-45.json\",\n",
    "\"5-redmi-04-03-2021_17-11-30.json\",\n",
    "\"6-redmi-17-03-2021_12-52-29.json\",\n",
    "\"7-redmi-17-03-2021_13-14-39.json\"]\n",
    "\n",
    "\n",
    "retaje = []\n",
    "for e in red_etaje: \n",
    "    json_file = os.path.join(datadir, e)\n",
    "    etaj = load_dataset_json(json_file)\n",
    "    retaje.append(etaj)\n",
    "\n",
    "petaje = []\n",
    "for e in pix_etaje: \n",
    "    json_file = os.path.join(datadir, e)\n",
    "    etaj = load_dataset_json(json_file)\n",
    "    petaje.append(etaj)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import braycurtis\n",
    "from scipy.stats import ks_2samp, chisquare\n",
    "import copy \n",
    "\n",
    "def merge_wifi_fingerprints(flist):\n",
    "    fingerprint = copy.deepcopy(flist[0])\n",
    "    for f2 in copy.deepcopy(flist[1:]):\n",
    "        if not \"wifi\" in f2.keys():\n",
    "            continue\n",
    "        for mac in f2[\"wifi\"].keys():\n",
    "            if not mac in fingerprint[\"wifi\"].keys():\n",
    "                fingerprint[\"wifi\"][mac] = f2[\"wifi\"][mac]\n",
    "                #fingerprint[\"wifi\"][mac]['rssi'] = []\n",
    "            else:\n",
    "                fingerprint[\"wifi\"][mac]['rssi'].extend(f2[\"wifi\"][mac]['rssi'])\n",
    "            fingerprint[\"wifi\"][mac]['rssi'].sort()    \n",
    "    return fingerprint\n",
    "\n",
    "\n",
    "def compare_locations(c1, c2, simil_method = braycurtis,  selection = 'Average', dif = False, direction=4):\n",
    "    rssi1 = []\n",
    "    rssi2 = []\n",
    "    w = [] #weight for braycurtis\n",
    "    \n",
    "    if (direction == 1):\n",
    "        # take the first fingerprint in the list \n",
    "        wifi1 = c1['fingerprints'][0]['wifi']\n",
    "        wifi2 = c2['fingerprints'][0]['wifi']\n",
    "\n",
    "        # take a random fingerprint in the list \n",
    "        #wifi1 = c1['fingerprints'][random.randint(0,3)]['wifi']\n",
    "        #wifi2 = c2['fingerprints'][random.randint(0,3)]['wifi']\n",
    "\n",
    "    if (direction == 2) :   \n",
    "        # first & third - as if measuring twice at 180 degrees\n",
    "        wifi1 = merge_wifi_fingerprints([c1['fingerprints'][0], c1['fingerprints'][2]])['wifi']\n",
    "        wifi2 = merge_wifi_fingerprints([c2['fingerprints'][0], c2['fingerprints'][2]])['wifi']\n",
    "    \n",
    "    if (direction == 4):  \n",
    "        #merge all existing fingerprints for each collection\n",
    "        wifi1 = merge_wifi_fingerprints(c1['fingerprints'])['wifi']\n",
    "        wifi2 = merge_wifi_fingerprints(c2['fingerprints'])['wifi']\n",
    "    \n",
    "    # all power received by the query\n",
    "    power1 = 0\n",
    "    for ap in wifi1:\n",
    "        power1 += np.sum(adjust_rssi(wifi1[ap]['rssi']))\n",
    "        \n",
    "    common_aps = list(set(wifi1.keys()) & set(wifi2.keys()))\n",
    "    #print(\"common aps=\", len(common_aps))\n",
    "    \n",
    "    # No APs in common -> similarity = 1\n",
    "    if not common_aps:\n",
    "        return 1\n",
    "\n",
    "    # TODO: find the best metric\n",
    "    # If not enough common APs -> similarity = 1\n",
    "    if len(common_aps) * 10 < len(wifi1.keys()) or len(common_aps) < 3:\n",
    "        return 1\n",
    "\n",
    "    for ap in common_aps:\n",
    "        \n",
    "        if selection == 'Bestdir':\n",
    "            for f1 in c1['fingerprints']: # all fingerprint dirs in the query \n",
    "                if not ap in f1['wifi'].keys():\n",
    "                    continue\n",
    "                m1 = np.average(adjust_rssi(f1['wifi'][ap]['rssi']))\n",
    "                best = 100                \n",
    "                for f2 in c2['fingerprints']: \n",
    "                    if not ap in f2['wifi'].keys():\n",
    "                        continue\n",
    "                    m2 = np.average(adjust_rssi(f2['wifi'][ap]['rssi']))\n",
    "                    if(math.fabs(m2-m1)) < best:  # find one dir with closest RSSI\n",
    "                        best = math.fabs(m2-m1)\n",
    "                        bestf = m2\n",
    "                rssi1.append(m1)\n",
    "                rssi2.append(bestf)\n",
    "                \n",
    "        # Take only the first RSSI value                \n",
    "        if selection == 'First':\n",
    "            rssi1.append(wifi1[ap]['rssi'][0])\n",
    "            rssi2.append(wifi2[ap]['rssi'][0])\n",
    "\n",
    "        # Make an average of all RSSI values\n",
    "        if selection == 'Average':\n",
    "            rssi1.append(np.average(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.average(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "            w.append(min(len(wifi1[ap]['rssi']), len(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Median':\n",
    "            rssi1.append(np.median(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.median(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Mean':\n",
    "            rssi1.append(np.mean(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.mean(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Std':\n",
    "            rssi1.append(np.std(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.std(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "\n",
    "        if selection == 'Max':\n",
    "            rssi1.append(np.max(adjust_rssi(wifi1[ap]['rssi'])))\n",
    "            rssi2.append(np.max(adjust_rssi(wifi2[ap]['rssi'])))\n",
    "            \n",
    "        if selection == 'KS':\n",
    "            _, p = ks_2samp(wifi1[ap]['rssi'], wifi2[ap]['rssi'])\n",
    "            rssi1.append(p)\n",
    "            rssi2.append(1.0)\n",
    "\n",
    "        if selection == 'Tempered':\n",
    "            rss_1.append(np.average(rssi_v[index][key]) * random.uniform(0.8, 1.2))\n",
    "            rss_2.append(np.average(rssi_v[r][key]) * random.uniform(0.8, 1.2))\n",
    "            \n",
    "    rssi11 = []\n",
    "    rssi22 = []\n",
    "    if selection != 'KS':\n",
    "        \n",
    "        if (dif == True):\n",
    "            #print(rssi1)\n",
    "            rssi11.append(np.diff(rssi1))\n",
    "            rssi22.append(np.diff(rssi2))\n",
    "            rssi1 = rssi11\n",
    "            rssi2 = rssi22        \n",
    "\n",
    "    #print(f\"1={rssi1}\\n2={rssi2}\\ncommon={common_aps}\")\n",
    "    #if selection != 'KS':\n",
    "    #    rssi1 = list(map(lambda x: x - np.mean(rssi1), rssi1))\n",
    "    #    rssi2 = list(map(lambda x: x - np.mean(rssi2), rssi2))\n",
    "    return simil_method(tuple(rssi1), tuple(rssi2))\n",
    "#        return simil_method(tuple(rssi1), tuple(rssi2))*sum(rssi1)/power1\n",
    "# weigh final result with used power/total power   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a matrix (list of lists) for a collection (etaj)\n",
    "# [point_index, index_of_closest_pt, dist_to_closest_pt, index_diff, dist_2_best_neighbor]\n",
    "def test_allvsall(collection, selection='Average', dif = False, direction = 4):\n",
    "    lc = len(collection)\n",
    "    #arr = [[0]*lc]*lc - nu merge!\n",
    "    arr = [[0 for i in range(lc)] for j in range(lc)]\n",
    "    for l in range(0, lc):\n",
    "        for c in range(0, l):\n",
    "            arr[l][c] = compare_locations(collection[l], collection[c], braycurtis, selection, dif, direction)\n",
    "            arr[c][l] = arr[l][c]\n",
    "        arr[l][l] = 1 # max \n",
    "\n",
    "   # print(\"#pt minpt mindist diff dist2nbr\")\n",
    "    listp = []\n",
    "    for l in range(0, lc):\n",
    "        mindist = min(arr[l])\n",
    "        index_of_min = arr[l].index(mindist)\n",
    "        diff = diff_modulo(l, arr[l].index(mindist), lc)\n",
    "        distl=arr[l][(l-1+lc)%lc]\n",
    "        distr=arr[l][(l+1)%lc]\n",
    "\n",
    "        #print(l, index_of_min, mindist, diff, min(distl, distr))\n",
    "        listp.append([l, index_of_min, mindist, diff, min(distl, distr)])\n",
    "    return listp\n",
    "\n",
    "\n",
    "\n",
    "def test_queryvsall(query, collections, selection='Average', dif = False, direction = 4):\n",
    "    \"\"\"\n",
    "    query = collection, an array or fingerprints \n",
    "    collections = aray of collection, can be a floor  \n",
    "    RETURNS (similarity, index, eu_distance)\n",
    "    \"\"\"\n",
    "    min = 1.0 \n",
    "    mini = -1; \n",
    "    for c in range(0, len(collections)):\n",
    "        d = compare_locations(query, collections[c], braycurtis, selection, dif, direction)\n",
    "        if d != 0 and d < min:\n",
    "            min = d \n",
    "            mini = c\n",
    "    return min,mini, \\\n",
    "            euclidean([query['x'], query['y'], query['z']],\\\n",
    "                       [collections[mini]['x'], collections[mini]['y'],collections[mini]['z']])\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  query = Pixel  \n",
    "#  DB = redmi \n",
    "cl_sim = []\n",
    "cl_steps = []\n",
    "cl_dist = []\n",
    "\n",
    "cl_sim_dif = []\n",
    "cl_steps_dif = []\n",
    "cl_dist_dif = []\n",
    "\n",
    "for e in range(0, len(retaje)):\n",
    "#for e in range(0, len(petaje)): \n",
    "    for p in range(0, len(petaje[e])):\n",
    "        sim, index, d =  test_queryvsall(petaje[e][p], retaje[e], 'Average', dif = False, direction = 4)\n",
    "        # print(sim, diff_modulo(p, index, len(petaje[e])), d)\n",
    "        cl_sim.append(sim)\n",
    "        cl_steps.append(diff_modulo(p, index, len(petaje[e])))\n",
    "        cl_dist.append(d)\n",
    "        \n",
    "        sim_dif, index_dif, d_dif =  test_queryvsall(petaje[e][p], retaje[e], 'Average', dif = True, direction = 4)\n",
    "        # print(sim, diff_modulo(p, index, len(petaje[e])), d)\n",
    "        cl_sim_dif.append(sim_dif)\n",
    "        cl_steps_dif.append(diff_modulo(p, index_dif, len(petaje[e])))\n",
    "        cl_dist_dif.append(d_dif)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = np.arange(0, 0.3, 0.01) # Bins of histogram - from 1 to 5 \n",
    "bin_width = b[1] - b[0]\n",
    "hist_sim, bins_out = np.histogram(np.array(cl_sim), b, density=False)\n",
    "hist_sim = hist_sim / len(cl_sim)\n",
    "hist_sim_dif, bins_out_dif = np.histogram(np.array(cl_sim_dif), b, density=False)\n",
    "hist_sim_dif = hist_sim_dif / len(cl_sim_dif)\n",
    "fig = plt.figure()\n",
    "plt.bar(b[:-1], hist_sim, width=bin_width, ec='k', alpha=0.5, label='avg')\n",
    "plt.bar(b[:-1], hist_sim_dif, width=bin_width, ec='k', alpha=0.5, label='avg dif')\n",
    "plt.xlabel(\"Similarity closest point query=Pixel DB=Redmi\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.title(\"{} {} \\n{}{}\".format(\"TOTAL floors \", len(retaje), len(cl_sim), \" points;\"))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"upper right\",shadow=True, fancybox=True)\n",
    "plt.show()\n",
    "#    fig.savefig(f\"{method}-{len(etaje)}.pdf\", bbox_inches='tight')\n",
    "#    print(\"Percentages: \", hist_away)\n",
    "\n",
    "b = np.arange(1, 15, 1) # Bins of histogram - from 1 to 5 \n",
    "bin_width = b[1] - b[0]\n",
    "hist_sim, bins_out = np.histogram(np.array(cl_steps), b, density=False)\n",
    "hist_sim = hist_sim / len(cl_sim)\n",
    "hist_sim_dif, bins_out_dif = np.histogram(np.array(cl_steps_dif), b, density=False)\n",
    "hist_sim_dif = hist_sim_dif / len(cl_sim_dif)\n",
    "fig = plt.figure()\n",
    "plt.bar(b[:-1], hist_sim, width=bin_width, ec='k', alpha=0.5, label='avg')\n",
    "plt.bar(b[:-1], hist_sim_dif, width=bin_width, ec='k', alpha=0.5, label='avg dif')\n",
    "plt.xlabel(\"closest point (steps) query=Pixel DB=Redmi\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.title(\"{} {} \\n{}{}\".format(\"TOTAL floors \", len(retaje), len(cl_sim), \" points;\"))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"upper right\",shadow=True, fancybox=True)\n",
    "plt.show()\n",
    "#fig.savefig(f\"{method}-{len(etaje)}.pdf\", bbox_inches='tight')\n",
    "#    print(\"Percentages: \", hist_away)\n",
    "\n",
    "\n",
    "\n",
    "b = np.arange(0, 10, 1) # Bins of histogram - from 1 to 5 \n",
    "bin_width = b[1] - b[0]\n",
    "hist_sim, bins_out = np.histogram(np.array(cl_dist), b, density=False)\n",
    "hist_sim = hist_sim / len(cl_sim)\n",
    "hist_sim_dif, bins_out_dif = np.histogram(np.array(cl_dist_dif), b, density=False)\n",
    "hist_sim_dif = hist_sim_dif / len(cl_sim_dif)\n",
    "fig = plt.figure()\n",
    "plt.bar(b[:-1], hist_sim, width=bin_width, ec='k', alpha=0.5, label='avg')\n",
    "plt.bar(b[:-1], hist_sim_dif, width=bin_width, ec='k', alpha=0.5, label='avg dif')\n",
    "plt.xlabel(\"closest point (meters) query=Pixel DB=Redmi\")\n",
    "plt.ylabel(\"PMF\")\n",
    "plt.title(\"{} {} \\n{} {} \\n{}{}\".format(\"Meters: median of avg\", np.median(cl_dist), \"median of avg dif\", np.median(cl_dist_dif), len(cl_sim), \" points;\"))\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"upper right\",shadow=True, fancybox=True)\n",
    "plt.show()\n",
    "#    fig.savefig(f\"{method}-{len(etaje)}.pdf\", bbox_inches='tight')\n",
    "#    print(\"Percentages: \", hist_away)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cdf=np.cumsum(hist_sim)\n",
    "cdf_dif=np.cumsum(hist_sim_dif)\n",
    "fig = plt.figure()\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.xlabel(\"closest point (meters) query=Pixel DB=Redmi\")\n",
    "plt.ylabel(\"CDF(%)\")\n",
    "plt.title(\"{}\".format(\"CDF - 4 directions - raw vs. difference\"))\n",
    "plt.plot(b[:-1], cdf, \"x-\", label='avg')\n",
    "plt.plot(b[:-1], cdf_dif, \"o-\", label='avg dif')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc=\"upper right\",shadow=True, fancybox=True)\n",
    "plt.show()\n",
    "fig.savefig(\"4directionAvgCDF.pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
